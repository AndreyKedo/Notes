- [Базовые понятия Elasticsearch](#базовые-понятия-elasticsearch)
  - [Индекс, тип, документ](#индекс-тип-документ)
  - [Полнотекстовый поиск и индексирование](#полнотекстовый-поиск-и-индексирование)
  - [Реплики и шарды](#реплики-и-шарды)
  - [Перевёрнутые индексы](#перевёрнутые-индексы)
- [Отображения индекса (mappings)](#отображения-индекса-mappings)
  - [Создание индекса](#создание-индекса)
  - [Простые типы данных](#простые-типы-данных)
  - [Составные типы данных](#составные-типы-данных)
  - [Специализированные типы данных](#специализированные-типы-данных)
  - [Мультиполя](#мультиполя)
  - [Получение текущих отображений](#получение-текущих-отображений)
- [Работа с данными](#работа-с-данными)
  - [Создание, изменение, удаление документов](#создание-изменение-удаление-документов)
- [Получение документов](#получение-документов)
  - [Вид запроса, параметры запроса и ответ](#вид-запроса-параметры-запроса-и-ответ)
  - [Query DSL](#query-dsl)
  - [Поиск](#поиск)
  - [Сортировка](#сортировка)
  - [Пагинация](#пагинация)
  - [Фильтрация](#фильтрация)
  - [Работа со scroll](#работа-со-scroll)
- [Анализаторы](#анализаторы)
  - [Встроенные анализаторы](#встроенные-анализаторы)
  - [Пользовательские анализаторы](#пользовательские-анализаторы)
  - [Составляющие анализатора](#составляющие-анализатора)
  - [Граф токенов](#граф-токенов)
  - [Нормализация](#нормализация)
  - [Анализатор индекса и анализатор поиска](#анализатор-индекса-и-анализатор-поиска)
- [Токенизаторы](#токенизаторы)
  - [Ориентированные на слова](#ориентированные-на-слова)
  - [Токенизаторы частичных слов](#токенизаторы-частичных-слов)
  - [Токенизаторы структурированного текста](#токенизаторы-структурированного-текста)
- [Настройки индекса (settings)](#настройки-индекса-settings)
- [Установка и использование Elasticsearch](#установка-и-использование-elasticsearch)
  

# Базовые понятия Elasticsearch

**Elasticsearch** (эластичный поиск) — распределённый (distributed), RESTful поисковой движок по всему тексту (full-text search).

*Elasticsearch* использует JSON-документы без схемы. Эти документы передаются при помощи REST API для сохранения их в хранилище и поиска.

*Elasticsearch* построен поверх поискового движка **Apache Lucene**, написанном на *Java*.

## Индекс, тип, документ
**Индекс** (Index) — эквивалент *базы данных* в SQL или NoSQL.

**Тип** (Type) — эквивалент *таблицы* в SQL или *коллекции* в NoSQL.

Имеется *тип по умолчанию*, который *создаётся автоматически* (`_doc`) при *создании индекса*.

**Документ** (Document) — эквивалент *строки* в SQL или *документа* в NoSQL.

Документы хранятся в JSON-формате
```js
 {
    "_index": "notes",
    "_type": "_doc",
    "_id": "sYKRT3EBYbOH8y9AHDYY",
    "_source": {
      "name": "Elasticsearch",
      "author": "Max-Starling",
      "date": "2020-04-07T23:15:50Z"
    }
}
```

## Полнотекстовый поиск и индексирование

**Полнотекстовый поиск** (Full text searching) — *поиск документов* не по их идентификаторам, а *по их содержимому*.

**Индексирование** (Indexing) в *поисковых системах* — процесс *добавления сведений* (о сайте) *роботом поисковой машины* в *базу данных*, которая используется для *полнотекстового поиска информации* на *проиндексированных сайтах*.

В рамках *Elasticsearch* **индексированием** называют *запись данных* в *индекс*.

## Реплики и шарды

*Индексы* обычно *разредяются* на *несколько подиндексов* (sub-indices), называемые **осколками**, **шардами** (shards). *Каждый шард хранит* какую-то *часть документов индекса*. 

**Шардинг** (Sharding) — процесс разбиения на шарды и одна из стратегий масштабирования баз данных.

*Шарды распределяются* между *несколькими узлами, экземплярами приложения* (Elasticsearch nodes). 

*Каждый шард* является *экземпляром дижка Lucene*. Таким образом *все данные хранятся в Lucene*, а *Elasticsearch распределённо управляет* этими *данными*.

*Количество шардов* указано в *настройках индекса* в *свойстве* `number_of_shards`.

*Резервная копия всех шардов* называется **репликой** (replica). Если *один экземпляр приложения падает* вместе с данными, которые на нём хранились, *реплика* позволяет *не терять* эти *данные*.

**Репликация** (Sharding) — процесс, при котором данные постоянно **реплицируются** (копируются) на один или несколько других серверов. Репликация тоже является стратегией масштабирования баз данных.

Количество *реплик* указано в *настройках индекса* в *свойстве* `number_of_replicas`.

## Перевёрнутые индексы

*Elasticsearch хранит данные* как **перевёрнутые индексы** (inverted indexes) *на диске*, что позволяет очень быстро искать данные.

Поисковой движок Apache Lucene реализует перевёрнутый индекс, используя структуру данных [**список с пропусками**](https://github.com/Max-Starling/Notes/blob/master/Algorithms-Structures.md#список-с-пропусками) (Skip List). Эта структура данных основана на связных списках, но по трудоёмкости сравнима с **двоичным деревом поиска** (B-tree).

Разработчики *Lucene* выбрали *список с пропусками вместо двоичного дерева*, поскольку он *требует меньшее число обращений* к *диску*. 

Индекс в Lucene очень похож на индекс в конце книги: указываются определённый список ключевых слов (важных определений) и рядом страницы, на которых они упоминаются.
![Index example](https://i.imgur.com/yIglkAe.jpg)

Аналогично работает и Google. Рядом с проиндексированными словами сохраняются ссылки на страницы. Таким образом их можно найти при поиске. Это же касается и Elasticsearch, только вместо ссылок на страницы используются ссылки на документы.

### Пример с разбиением на слова

Посмотрим, как обратные индексы работают на примере. 

Пусть у нас есть два текста.
* `I don't like to work alone`.  
* `I often work on weekends`.

Разобьём их на слова и выберем только уникальные слова из обоих текстов.

Множество уникальных слов будет следующим: `I`, `don't`, `like`, `to`, `work`, `alone`, `often`, `on`, `weekends`.

Сохраним каждое уникальное слово в память, а рядом с ним — ссылки на те документы, которые используют это слово.

| Слово     | Документ #1 | Документ #2 |
| --------- | ----------- | ----------- |
| I         |     +       |      +      |
| don't     |     +       |             |
| like      |     +       |             |
| to        |     +       |             |
| work      |     +       |      +      |
| alone     |     +       |             |
| often     |             |      +      |
| on        |             |      +      |
| weekends  |             |      +      |

Теперь произведём поиск по словам. Документ либо содержит слово, либо не содержит.

Например, поиск по слову `work` выдаст оба документа, по слову `like` — только первый, по слову `often` — только второй.

Если ввести искать по двум словам одновремено `often` и `alone`, то выдадутся оба документа.

| Слово     | Документ #1 | Документ #2 |
| --------- | ----------- | ----------- |
| alone     |     +       |             |
| often     |             |      +      |


# Отображения индекса (mappings)

**Отображение** (mapping) — процесс, определяющий *как документ* и *поля в нём хранятся* и *индексируются*.

*Отображения задаются* при *создании индекса* в *поле* `mappings`. Они *содержат свойства документов* и их всевозможные *типы*.

Если `mappings` не задаётся при создании индекса, то Elasticsearch создаёт его автоматически в режиме реального времени на основании данных индокументов, которые сохраняются в индекс.

## Создание индекса

Для создания используется PUT-запрос с названием индекса.
```http
PUT <ELASTICSEARCH_URL>/index_name
```
```js
/* response body */
{
  "acknowledged": true,
  "shards_acknowledged": true,
  "index": "users"
}
```

## Простые типы данных
* **Строковые** (string): `text`, `keyword`.
* **Числовые** (Numberic): `long`, `integer`, `short`, `byte`, `double`, `float`, `half_float`, `scaled_float`.
* **Логический** (Boolean): `boolean`.
* **Дата** (Date): `date`.
* **Бинарный** (Binary): `binary`.
* **Диапазон** (Range): `integer_range`, `float_range`, `long_range`, `double_range`, `date_range`.

### Тип данных text

Строковый тип `text` используется для индексирования **полнотекстовых значений** (full-text values). Примерами полнотекстовых значений являются поля: название, сообщение, описание.

*Полнотекстовые значения* **анализируются**, то есть обрабатываются перед *индексированием*. 

Каждое *полнотекстовое поле проходит перед индексированием* через **анализатор** (analyzer), который *конвертирует строку* в *список отдельных термов* (list of individual terms), затем этот *список индексируется*, а *поле* называют **проанализированным** (analyzed). 

**Анализирование** (analysis) позволяет *Elasticsearch* *искать отдельные слова* в *каждом полнотекстовом поле*.

*Поля текстового типа* *не используются* для *сортировки*, обычно *не используются* для *агрегаций*.

Задание типа `text`.
```http
PUT <ELASTICSEARCH_URL>/index_name
Content-Type: application/json

{
  "mappings": {
    "properties": {
      "description": {
        "type":  "text"
      }
    }
  }
}
```

### Тип данных keyword

*Строковый тип* `keyword` (ключевое слово) используется для *индексирования* таких *значений*, как: `ID`, `email`, `hostname`, `status code`, `tag` и прочих. Эти *значения используются* для *фильтрации*, *сортировки* и *агрегации*. 

Поля типа `keyword` *не анализируются*. Они *ищутся только по точному значению, совпадению* (exact value). Например, нельзя найти `tom@gmail.com` по слову `tom` или `gmail`.

Задание типа `keyword`.
```http
PUT <ELASTICSEARCH_URL>/index_name
Content-Type: application/json

{
  "mappings": {
    "properties": {
      "email": {
        "type":  "keyword"
      }
    }
  }
}
```

## Составные типы данных
* **Объект** (Object): `object`. Для JSON-объекта.
* **Вложенный** (Nested): `nested`. Для массива JSON-объектов.

### Массив

**Массив** (Array) в Elasticsearch не существует как отдельная сущность, поскольку любое поле может иметь одно или несколько значений по умолчанию. Тем не менее, все эти значения должны быть одного типа.

* Массив строк: `["1", "two"]`.
* Массив чисел: `[1, 7]`.
* Массив объектов `[{ "name": "John", "experience": 5 }, { "name": "Sam", "experience": 3 }]`.

В массиве объектов нельзя выделить конкретный объект. При такой необходимости нужно использовать тип `nested`.

Массивы смешанных типов не поддерживаются: `[1, "two"]`.

Пустой массив интерпретируется как отсутствующее значение (поле без значений).

Вставка объекта с массивом `tags`.
```http
PUT <ELASTICSEARCH_URL>/index_name/_doc/1
Content-Type: application/json

{
  "message": "The problem with useEffect",
  "tags":  [ "js", "react", "react-hooks" ]
}
```

### Особенность массива объектов

В массиве объектов Elasticsearch не рассматривает объекты как независимые сущности, поэтому Elasticsearch просто разбивает их на список полей и значений.

Например, вставка следующего массива объектов
```http
PUT <ELASTICSEARCH_URL>/index_name/_doc/1
Content-Type: application/json

{
  "user" : [ 
    {
      "firstName" : "Max",
      "lastName" :  "Starling"
    },
    {
      "firstName" : "Richard",
      "lastName" :  "Stone"
    }
  ]
}
```
будет преобразована в два поля с несколькими значениями.
```js
{
  "user.firstName" : [ "Max", "Richard" ],
  "user.lastName" :  [ "Starling", "Stone" ]
}
```
Связь между полями `firstName` и `lastName` теряется и они уже больше не являются одним объектом.

Поэтому при поиске следующий запрос не выдаст совпадений.
```js
[
  { "match": { "user.firstName": "Max" }},
  { "match": { "user.lastName": "Starling" }}
]
```

### Сравнение массива объектов и вложенного типа

**Вложенный тип данных** (Nested datatype) — специальный подтип объекта (`object`), который позволяет индексировать массив JSON-объектов таким образом, чтобы объекты можно было получать отдельно друг от друга.


## Специализированные типы данных
* **IP**: `ip`. Для IPv4 и IPv6 адресов.
* **Completion** (Completion datatype): `completion`. Для автозаполнения предложений.
* **Join**: `join`. Для создания отношений между документами одного индекса.
* **Search-as-you-type**: `search_as_you_type`. Для поиска по мере ввода.

## Мультиполя

Elasticserach предоставляет возможность *хранить одно и то же полt несколькими способами* для *разных целей*. Такое *поле* называется **мультиполем** (multi-field).

Например, *текстовое поле* может быть *одновременно* представлено *типом* `text` для *полтотекстового поиска* и типом `keyword` *для сортировки* и *агрегации*.

Настройка мультиполя.
```http
PUT <ELASTICSEARCH_URL>/index_name
Content-Type: application/json

{
  "mappings": {
    "properties": {
      "position": {
        "type": "text",
        "fields": {
          "keyword": { 
            "type":  "keyword"
          }
        }
      }
    }
  }
}
```
Чтобы использовать поле `position` как ключевое слово, необходимо писать `position.keyword`, при использовании `position` будет срабатывать полнотекстовый поиск.

Поле `keyword` можно назвать как угодно (например, `raw`).
```http
"fields": {
    "raw": { 
      "type":  "keyword"
    }
  }
}
```
Тогда использование поля `position` в качестве ключевого слова: `position.raw`.

### Получение текущих отображений

Текущие *отображения индекса* можно *получить* по *GET-запросу* `_mappings`.
```http
GET <ELASTICSEARCH_URL>/index_name/_mappings
```
```js
/* response body */
{
  "index_name": {
    "mappings": {
      "properties": {
        "job": {
          "type": "text",
          "fields": {
            "keyword": {
              "type": "keyword",
              "ignore_above": 256
            }
          }
        },
        "name": {
          "type": "text",
          "fields": {
            "keyword": {
              "type": "keyword",
              "ignore_above": 256
            }
          }
        }
      }
    }
  }
}
```
По ответу на запрос можно понять, что в схеме документа индекса `users` содержится два поля `job` и `name`, у которых задан тип `text`.

# Работа с данными

## Создание, изменение, удаление документов
* Создание типа (`user`) и документа в нём.
```http
POST <ELASTICSEARCH_URL>/users/user
Content-Type: application/json

{
  "name": "Alen Stone",
  "job": "Full-stack Enginer"
}
```
```js
/* response body */
{
  "_index": "users",
  "_type": "user",
  "_id": "H3tVi3ABpFL-9AlTbAgj",
  "_version": 1,
  "result": "created",
  "_shards": {
      "total": 2,
      "successful": 1,
      "failed": 0
  },
  "_seq_no": 0,
  "_primary_term": 1
}
```
* Обновление документа (типа `user` по id).
```http
PUT <ELASTICSEARCH_URL>/users/user/H3tVi3ABpFL-9AlTbAgj
Content-Type: application/json

{
  "name": "Richard Stone",
  "job": "Full-stack Enginer"
}
```
```js
/* response body */
{
  "_index": "users",
  "_type": "user",
  "_id": "H3tVi3ABpFL-9AlTbAgj",
  "_version": 3,
  "result": "updated",
  "_shards": {
      "total": 2,
      "successful": 1,
      "failed": 0
  },
  "_seq_no": 2,
  "_primary_term": 1
}
```
* Удаление документа (типа `user` по id).
```http
DELETE <ELASTICSEARCH_URL>/users/user/H3tVi3ABpFL-9AlTbAgj
```
```js
/* response body */
{
  "_index": "users",
  "_type": "user",
  "_id": "H3tVi3ABpFL-9AlTbAgj",
  "_version": 4,
  "result": "deleted",
  "_shards": {
      "total": 2,
      "successful": 1,
      "failed": 0
  },
  "_seq_no": 5,
  "_primary_term": 1
}
```
* Создание нескольких документов (типа `user`).  
В конце BODY запроса обязателен переход на новую строку.
```http
POST <ELASTICSEARCH_URL>/users/user/_bulk
Content-Type: application/json

{"index":{}}
{"name":"Harry Smith","job":"Dev Ops"}
{"index":{}}
{"name":"Sam Brave","job":"QA"}
   
```
```js
/* response body */
{
  "took": 26,
  "errors": false,
  "items": [
    {
      "index": {
          "_index": "users",
          "_type": "user",
          "_id": "Jntsi3ABpFL-9AlTdggH",
          "_version": 1,
          "result": "created",
          "_shards": {
              "total": 2,
              "successful": 1,
              "failed": 0
          },
          "_seq_no": 7,
          "_primary_term": 1,
          "status": 201
      }
    },
    {
      "index": {
          "_index": "users",
          "_type": "user",
          "_id": "J3tsi3ABpFL-9AlTdggH",
          "_version": 1,
          "result": "created",
          "_shards": {
              "total": 2,
              "successful": 1,
              "failed": 0
          },
          "_seq_no": 8,
          "_primary_term": 1,
          "status": 201
      }
    }
  ]
}
```

# Получение документов

Для получения документов индекса используется запрос `/_search`.

## Вид запроса, параметры запроса и ответ

### Все документы

Получить информацию о всех документах можно отправив GET-запрос, ничего не указывая.
```http
GET <ELASTICSEARCH_URL>/users/_search
```
Ответ выглядит следующим образом. 
```js
/* response body */
{
  "took": 80,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 2,
      "relation": "eq"
    },
    "max_score": 1.0,
    "hits": [
        {
          "_index": "users",
          "_type": "user",
          "_id": "Jntsi3ABpFL-9AlTdggH",
          "_score": 1.0,
          "_source": {
            "name": "Harry Smith",
            "job": "Dev Ops"
          }
        },
        {
          "_index": "users",
          "_type": "user",
          "_id": "J3tsi3ABpFL-9AlTdggH",
          "_score": 1.0,
          "_source": {
              "name": "Sam Brave",
              "job": "QA"
          }
        }
    ]
  }
}
```
Наиболее полезная информация лежит в свойстве `hits`: `hits.total.value` - количество всех докуметров, удовлетворяющих поиску, `hits.hits` - массив самих документов (хранятся в `_source`) и дополнительной информации о них. По умолчанию возвращается только 10 документов (см. [Пагинация](#пагинация)). 

### По конкретному слову (все поля документа)

Поиск по конкретному слову (слову `ops`) во всех полях (и `name`, и `job`).
```http
GET <ELASTICSEARCH_URL>/users/_search?q=ops
```

### По конкретному слову (конкретное поле)

Поиск по конкретному слову (слову `ops`) в конкретном поле (`name`).
```http
GET <ELASTICSEARCH_URL>/users/_search?q=name:sam
```

## Query DSL

Elasticsearch предоставляет **Query DSL** (Domain Specific Language) — предметно-ориентированный язык, позволяющий описывать запрос `query` в формате JSON и отправлять его в теле запроса (request body). Тело можно отравлять даже с GET-запросами.

Создатели Elasticsearch предлагают рассматривать Query DSL как **абстрактное синтаксическое дерево** (AST, Abstract Syntax Tree) **запросов**, которое имеет два типа **предложений** (clauses):
* **Листовые, конечные** (leaf query clauses). Предназначены для поиска определённого значения в определённом поле. Пример: `match`, `term`, `range`.
* **Составные** (compound query clauses). Предназначены для логического объединения листовых и других составных предложений. Пример: `bool`.

Например, Query DSL позволяет GET-запрос следующего вида
```http
GET <ELASTICSEARCH_URL>/users/_search?q=name:sam
```
отправлять вот так
```http
GET <ELASTICSEARCH_URL>/users/_search
Content-Type: application/json

{
  "query": {
    "match" : {
      "name" : "sam"
    }
  }
}
```

## Поиск

### Все документы

### По одному полю

```http
GET <ELASTICSEARCH_URL>/users/_search
Content-Type: application/json

{
  "query": {
    "match" : {
      "name" : "sam"
    }
  }
}
```

### По нескольким полям
```http
GET <ELASTICSEARCH_URL>/users/_search
Content-Type: application/json

{
 "query": {
   "multi_match": {
     "query" : "sam",
     "fields" : ["firstName", "lastName"]
   }
}
```

## Сортировка

Elasticsearch позволяет при поиске *сортировать* документы *по одному* или *нескольким полям*. 

За **сортировку** (sort) отвечает поле `sort`. Возможна может производиться **по возрастанию** (`asc`, ascending) и **по убыванию** (`desc`, descending).
```js
{
  "sort" : [
    { "likes" : { "order" : "desc" } },
    { "date" : { "order" : "asc" } }
  ]
}
```

При сортировке по нескольким полям важнее является то поле, которое указано первым в массиве.

### Сортировка полей-массивов

Elasticsearch также поддерживает сортировку полей, значениями которых являются массивы. В этом случае доступны следующие режимы (`mode`)
* `min` — сортировка по минимальным значениям массивов.
* `max` — сортировка по максимальным значениям массивов.
* `avg` — сортировка по средним значениям массивов.
* `sum` — сортировка по сумме значений массива.

```js
{
  "sort" : [
    { "values" : { "order" : "desc", "mode": "avg" } },
  ]
}
```

### Пример сортировки фильмов по рейтингу и дате

Создание индекса `films` с полями название, дата, рейтинг.
```HTTP
PUT <ELASTICSEARCH_URL>/films
Content-Type: application/json

{
  "mappings": {
    "properties": {
      "name": { "type": "keyword" },
      "date": { "type": "date" },
      "rating": { "type": "float" }
    }
  }
}
```
Вставка трёх фильмов в индекс.
```HTTP
PUT <ELASTICSEARCH_URL>/films/_doc/_bulk
Content-Type: application/json

{ "index":{} }
{ "name": "film 1", "date": "2020-05-01T12:10:30Z", "rating": 4.5 }
{ "index":{} }
{ "name": "film 2", "date": "2020-06-30T16:00:45Z", "rating": 4.5 }
{ "index":{} }
{ "name": "film 3", "date": "2020-04-07T23:15:50Z", "rating": 4.7 }

```

Сортировка фильмов по убыванию рейтинга и даты.
```HTTP
GET <ELASTICSEARCH_URL>/films/_doc/_search
Content-Type: application/json

{
  "sort" : [
    { "rating" : { "order" : "desc" } },
    { "date" : { "order" : "desc" } }
  ]
}
```
Результат: `[film 3, film 2, film 1]`.

`film 3` является самым старым, но имеет выше рейтинг, а рейтинг приоритетнее даты, поскольку указан раньше в массиве.
`film 2` имеет такой же рейтинг, как и `film 1`, но по дате он новее.

## Пагинация

Пагинация является частью запроса `_search`.

Свойство `size` определяет количество возвращаемых документов. По умолчанию оно равно 10.

Свойство `from` отвечает за смещение документов (количество документов, которые должны быть пропущены).

Добавим свойство `size` к запросу с сортировкой фильмов.
```http
GET <ELASTICSEARCH_URL>/films/_doc/_search
Content-Type: application/json

{
  "sort" : [
    { "rating" : { "order" : "desc" } },
    { "date" : { "order" : "desc" } }
  ],
  "size": 2
}
```
Результат: `[film 3, film 2]`.

Добавим теперь свойство `from`.
```http
GET <ELASTICSEARCH_URL>/films/_doc/_search
Content-Type: application/json

{
  "sort" : [
    { "rating" : { "order" : "desc" } },
    { "date" : { "order" : "desc" } }
  ],
  "size": 2,
  "from": 1
}
```
Результат: `[film 2, film 1]`.

## Фильтрация

Филтрация является частью `query`.

Фактически, свойство `bool` предоставляет логические (boolean) операции для фильтрации
* `must` — аналог логического И (AND).
* `should` — аналог логического ИЛИ (OR).
* `must_not` — аналог логического НЕ (NOT).

Все эти свойства могут принимать как объекты с условиями, так и массивы с этими объектами.
```js
{
  "query" : {
    "bool" : {
      "must": [{
        "term": {
          "position": "Software Enginer"
        }
      }, {
        "terms": {
          "technology": ["React", "Vue"]
        }
      }],
      "should": [{
        "range": {
          "experience": {
            "gte": "1 year"
          }
        }
      }, {
        "range": {
          "desiredSalary": {
            "lte": "1000 USD"
          }
        }
      },
      "must_not": {
        "range": {
          "age": {
            "lte": 25
          }
        }
      }
    }
  }
}
```

# Анализаторы

**Анализаторы** (Analyzers) определяют способ, которым данные будут анализироваться перед индексацией.

**Анализ текста** (Text analysis) — процесс преобразования обычного текста в структурированный формат, оптимизированный для поиска. Используется, когда установлен тип данных `text`.

После анализа текст поля разделяется на **термы** (terms). Таким образом, после анализа поле представлено в виде **списка термов** (list of terms), в котором оно и индексируется.

## Встроенные анализаторы

Elasticsearch предоставляет набор **встроенных анализаторов** (build-in analyzers).

Для их будем анализировать фразу `"- How old are you? - I'm 17."`.

Чтобы проверить, как работает конкретный анализатор, можно отправить следующий запрос.
```http
GET <ELASTICSEARCH_URL>/_analyze
Content-Type: application/json

{ 
  "analyzer": "analyzer_name",
  "text":"- How old are you? - I'm 17."
}
```

* **Стандартный**: `standard`. Используется по умолчанию. Разбивает текст на слова, переводит их в нижний регистр (`lowercase`), удаляет знаке препинания, при необходимости удаляет стоп-слова.
```js
/* terms */
["how", "old", "are", "you", "i'm", "17"]
```
* **Простой**: `simple`. Разделяет слова каждый раз, когда встречает не букву. Все термы переводятся в нижний регистр.
```js
/* terms */
["how", "old", "are", "you", "i", "m"]
```
* **Стоп-анализатор**: `stop`. Как `simple`, но с возможностью удалять стоп-слова. По умолчанию используются стоп-слова английского языка (вспомогательные глаголы, предлоги и так далее).
```js
/* terms */
["how", "old", "you", "i", "m"]
```
* **Пробельный**: `whitespace`. Разделяет текст, когда находит пробельные символы.
```js
/* terms */
["-", "How", "old", "are", "you?", "-", "I'm", "17."]
```
* **Анализатор ключевых слов**: `keyword`. Принимает текст и его возвращает как есть.
```js
/* terms */
["- How old are you? - I'm 17."]
```
* **Языковой**: `english`, `french`. Анализирует текст соответственно специфике языка. Удаляет стоп-слова, характерные языку. Переводит в нижний регистр.
```js
/* terms */
["how", "old", "you", "i'm", "17"]
```
* **Шаблонный**: `pattern`. Для разделения текста на термы использует регулярные выражения. По умолчанию используется регулярное выражение `\W+` (всё, что не может быть словом). Переводит в нижний регистр.
```js
/* terms */
["how", "old", "are", "you", "i", "m", "17"]
```

## Пользовательские анализаторы

Чтобы расширить функциональность встроенного анализатора (например, заменить стоп-слова или заменить регулярное выражение), необходимо создать **пользовательский анализатор** (custom analyzer) в настройках индекса (`settings`), что обычно делается при создании индекса.

Пользовательские анализаторы существуют в пределах индекса.

Например, создадим пользовательский анализатор, который игнорирует слово `old`. Для этого добавим его в поле `stopwords`.
```http
PUT <ELASTICSEARCH_URL>/index_name
Content-Type: application/json

{
  "settings": {
    "analysis": {
      "analyzer": {
        "custom_stop": {
          "type": "stop",
          "stopwords": ["old"]
        }
      }
    }
  }
}
```
Проверим, как анализируется текст `"- How old are you? - I'm 17."`.
```http
GET <ELASTICSEARCH_URL>/index_name/_analyze
Content-Type: application/json

{ 
  "analyzer": "analyzer_name",
  "text":"- How old are you? - I'm 17."
}
```
```js
/* terms */
["how", "are", "you", "i", "m"]
```

Для более гибкой настройки пользовательских анализаторов необходимо ознакомиться с блоками, из которых состоит каждый анализатор.

## Составляющие анализатора

*Анализатор* является *пакетом*, который *состоит* из *нескольких строительных блоков*: *фильтры символов*, *токенизатор*, *фильтры токенов*.

При *преобразовании текста* эти *блоки вызываются* в *указанном выше порядке*.

### Фильтр символов

**Фильтр символов** (Character filter) принимает оригинальный текст в качестве потока символов и трансформирует этот поток, добавляя, удаляя и изменяя символы.

Например, римские цифры (`I`, `II`, `III`) могут переводиться в арабские (1, 2, 3).

У анализатора может быть несколько фильтров символов или не быть вообще. Они применяются в указанном порядке.

### Токенизатор

**Токенизатор** (Tokenizer) *принимает поток символов* (stream of characters), *разбивает его* на *отдельные токены* (individual tokens) и *возвращает поток токенов*. Чаще всего токенами являются отдельные слова. 

*Процесс разбиения потока символов* на *токены* называется **токенизацией** (tokenization).

Именно *благодаря токенизации доступен полтотекстовый поиск*, ведь *каждый токен индексируется отдельно*.

Ранее было показано, как *токенизаторы встроенных анализаторов* разделяют текст на токены (термы).

*Токенизатор* также *отвечает за порядок термов* (порядок может меняться).

*Один анализатор имеет ровно один токенизатор*.

### Фильтр токенов

**Фильтр токенов** (Token filter) принимает поток токенов (stream of tokens) и транмформирует его, удаляя, добавляя и изменяя токены.

Например, фильтр токенов `lowercase` переводит все токены в нижний регистр, фильтр `stop` удаляет стоп-слова, фильтр `synonym` добавляет синонимы в поток токенов.

У анализатора может быть несколько фильтров токенов или не быть вообще. Они применяются в указанном порядке.

<!-- Можно заменить, что английские стоп-слова перестали игнорироваться, поскольку произошла их перезапись массивом `["old"]`. Чтобы это исправить, можно использовать.
_english_ -->

## Граф токенов

Когда токенизатор превращает поток символов в поток токенов, он запоминает **позицию** (`position`) каждого токена в потоке и число позиций (`positionLength`), которые охватывает токен.

Это позволяет построить **ориентированный** (имеющий направление движения) **ациклический** (без циклов) **граф**, который называется **графом токенов** (token graph).

Каждая позиция представляет **вершину графа** (node).

Каждый токен представляет **дугу графа** (edge), указывающую на следующую позицию.

```js
/* граф токенов для текста "Hello our users!" после токенизации */

   hello      our       users    
0 ------> 1 -------> 2 -------> 3
```

Фильтры токенов могут добавлять новые токены (например, синонимы) в поток токенов, а значит и в граф токенов.

Синонимы записываются на ту же позицию, что и существующие токены.
```js
/* граф токенов для текста "Hello our users!" после токенизации
и фильтрации фильтром токенов с синонимами */

   hello      our       users    
0 ------> 1 -------> 2 -------> 3
    hi                 clients
```

### Многопозиционные токены

По умолчанию токен занимает только одну позицию, то есть его `positionLength` равняется 1.

Но некоторые синонимы могут занимать несколько позиций. Например, расшифровки аббревиатур (CSS, Cascading Style Sheets).
```js
  cascading      style       sheets         is          ...
0 ----------> 1 --------> 2 ---------> 3 ---------> 4 --------> 5
|                                      |
----------------------------------------
                  css
```

Фильтры, которые могут добавлять многопозиционные токен, называются **фильтрами токенов графа** ( graph token filters). Такими являются фильтры `synonym_graph` и `word_delimiter_graph`.

## Нормализация

В то время, как благодаря токенизации доступен полтотекстовый поиск, каждый отдельный токен при поиске сравнивается посимвольно.

* При поиске `How`, токен `how` не пройдёт проверку на совпадение.  
* При поиске `user`, токен `users` не пройдёт проверку на совпадение. 
* При поиске `hello`, токен `hi` не пройдёт проверку на совпадение.

Чтобы этого избежать, можно **нормализовать** (normalize) данные, то есть привести их к стандартному формату. Таким образом токены не будут точно совпадать (not exact match), но будут достаточно похожи, чтобы попасть в результат поиска.

К примеру, токен `Hello` может быть переведено в нижний регистру (`be lowercased`), `users` может быть приведён к его корневому слову `user` (stemmed), `hello` и `hi` являются синонимами и могут индексироваться как единственное слово `hello`.

## Анализатор индекса и анализатор поиска

*Анализ текста* осуществляется *дважды*
* при *индексации документа* (Index time)
* во *время поиска* (Search time, query time).

**Анализатор индекса** (Index analyzer) анализирует текстовые данные перед индексацией.

**Анализатор поиска** (Search analyzer) анализирует текс поискового запроса (`query`).

В большитсве случаев эти анализаторы должны иметь одинаковый набор правил токенизации и нормализации.

Например, при текст `"Hello our USERS!"` может быть преобразован анализатором индекса в `[hello, our, user]`, а текст поискового запроса `"Hi user"` — анализатором поиска в `[hello, user]`.

| Слово     | Поиск       | Индекс      |
| --------- | ----------- | ----------- |
| hello     |     +       |      +      |
| our       |             |      +      |
| user      |     +       |      +      |

Тогда документ со значением `"Hello our USERS!"` в текстовом поле попадёт в результат поиска по запросу `"Hi user"`.

### Разные анализаторы поиска и инекса 

Иногда может появиться необходимость использовать разные анализаторы индекса и поиска.

Например, когда мы хотим, чтобы убрать из поиска некоторые нежелательные результаты.

В этом случае можно указать отдельный анализатор для поиска.
```http
GET <ELASTICSEARCH_URL>/index_name/_search
Content-Type: application/json

{
  "query": {
    "match": {
      "message": {
        "query": "Hi user",
        "analyzer": "stop"
      }
    }
  }
}
```

Можно также задать разные анализаторы для конкретного поля при создании индекса в `mappings`.
```http
PUT <ELASTICSEARCH_URL>/index_name
Content-Type: application/json

{
  "mappings": {
    "properties": {
      "title": {
        "type": "text",
        "analyzer": "whitespace",
        "search_analyzer": "simple"
      }
    }
  }
}
```

# Токенизаторы

В главе **[Составляющие анализатора](#составляющие-анализатора)** было рассказано, что такое *токенизатор*.

Помимо перечисленных ранее функций, *токенизаторы* также *задают* **тип токенов** (token type). 

*Простые токенизаторы* *разбиват текст* на *слова* и задают *тип* `word`. *Другие токенизаторы* могут задавать *типы* `<ALPHANUM>`, `<HANGUL>`, `<NUM>`.

*Виды токенизаторов*
* *Ориентированные на слова*.
* *Токенизаторы частичных слов*.
* *Токенизаторы структурированного текста*.

## Ориентированные на слова

**Ориентированные на слова токенизаторы** (Word oriented tokenizer) разбивают текст на отдельные токены, которые явяются словами. 

Задаваемый тип токенов: `word`.

## Токенизаторы частичных слов

**Токенизаторы частичных слов** (Partial word tokenizer) разбивают текст или слова на маленькие фрагменты для проверки на частичное совпадение слов.

### N-gram

### Edge n-gram

## Токенизаторы структурированного текста

**Токенизаторы структурированного текста** (Structured text tokenizer) обычно используются не для полнотекстового поиска, а для идентификаторов (`id`, `email`, `phone` и так далее).


# Настройки индекса (settings)

У каждого индекса может быть какой-то набор настроек.

Текущие настройки индекса можно получить по GET-запросу `_settings`.
```http
GET <ELASTICSEARCH_URL>/users/_settings
```

```js
/* response body */
{
  "users": {
    "settings": {
      "index": {
        "number_of_shards": "1",
        "blocks": {
          "read_only_allow_delete": "true"
        },
        "provided_name": "users",
        "creation_date": "1582885295047",
        "number_of_replicas": "1",
        "uuid": "cNAP5avkRueTAkUGNxsHew",
        "version": {
          "created": "7030299"
        }
      }
    }
  }
}
```

*Количество шардов* указано в *настройках индекса* в *свойстве* `number_of_shards`.

Количество *реплик* указано в *настройках индекса* в *свойстве* `number_of_replicas`.


# Установка и использование Elasticsearch

* [Скачать архив](https://www.elastic.co/guide/en/elasticsearch/reference/current/install-elasticsearch.html#install-elasticsearch).
* Разархивировать и запустить `bin\elasticsearch` или `bin\elasticsearch.bat` (в зависимости от операционной системы).
* Поскольку общение с Elasticserach идёт при помощи HTTP-запросов, можно использовать Postman (или что-то похожее) и делать запросы на `http://localhost:9200`.
